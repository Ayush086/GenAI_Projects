{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8e06ff",
   "metadata": {},
   "source": [
    "### Multimodal RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e834431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Generative-AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "from langchain_core.documents import Document\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d88d23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Generative-AI\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPSdpaAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HUgging face setup (CLIP model)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGING_FACE_API_KEY\"] = os.getenv(\"HUGGING_FACE_API_KEY\")\n",
    "\n",
    "# init clip model for unified embeddings\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") # used to create text + image into embeddings\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32') # to structure the input format for CLIP model\n",
    "\n",
    "clip_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bfbc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## Helper functions to create embeddings\n",
    "def embed_image(image_data):\n",
    "    # if path -> fetch the image and convert\n",
    "    if isinstance(image_data, str):\n",
    "        image = Image.open(image_data).convert(\"RGB\")\n",
    "    else: image = image_data\n",
    "\n",
    "    inputs = clip_processor(images=image, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        # normalize embeddings to unit vectors\n",
    "        features = features / features.norm(dim=-1, keepdim=True)\n",
    "        return features.squeeze().numpy() # return in  numpy array\n",
    "        \n",
    "def embed_text(data):\n",
    "    inputs = clip_processor(\n",
    "        text=data,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length = 77 # CLIP's max token length\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_text_features(**inputs)\n",
    "        # normalize embeddings\n",
    "        features = features / features.norm(dim= -1, keepdim=True)\n",
    "        return features.squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854f7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process the pdf\n",
    "pdf_path = './multimodal_sample.pdf'\n",
    "doc = pymupdf.open(pdf_path)\n",
    "\n",
    "all_docs = [] # docs will be stored here\n",
    "all_embeddings = [] # embeddings will be stored here\n",
    "image_data_store = {} # store actual image data\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "519390ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, page in enumerate(doc):\n",
    "    ## process text\n",
    "    text = page.get_text()\n",
    "    if text.strip():\n",
    "        temp_doc_for_splitting = Document(page_content=text, metadata={'page': idx, 'type': 'text'})\n",
    "        text_chunks = text_splitter.split_documents([temp_doc_for_splitting])\n",
    "\n",
    "        # embed chunk using clip\n",
    "        for chunk in text_chunks:\n",
    "            embeddings = embed_text(chunk.page_content)\n",
    "            all_embeddings.append(embeddings)\n",
    "            all_docs.append(chunk)\n",
    "\n",
    "    ## process image\n",
    "    for img_idx, img in enumerate(page.get_images(full=True)):\n",
    "        try:\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image['image']\n",
    "            \n",
    "            # s1: convert pdf iamge to PIL format\n",
    "            PIL_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "            \n",
    "            image_id = f\"page_{idx}_image_{img_idx}\"\n",
    "\n",
    "            # s2: store as base64 for LLM\n",
    "            buffered = io.BytesIO()\n",
    "            PIL_image.save(buffered, format='PNG')\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "            image_data_store[image_id] = img_base64\n",
    "\n",
    "            # s3: create clip embeddings for retrieval\n",
    "            embeddings = embed_image(PIL_image)\n",
    "            all_embeddings.append(embeddings)\n",
    "            \n",
    "            image_doc = Document(\n",
    "                page_content = f'[Image: {image_id}]',\n",
    "                metadata = {'page': idx, \"type\": \"image\", \"image_id\": image_id}\n",
    "            )\n",
    "            all_docs.append(image_doc)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_idx} on page {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c14302c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-2.67243991e-03,  1.28299948e-02, -5.18313870e-02,  4.14879471e-02,\n",
       "        -2.33941860e-02, -7.55864428e-03, -3.67659405e-02,  1.19710669e-01,\n",
       "         8.52081329e-02,  2.05423264e-03, -1.11534819e-02, -1.29592139e-02,\n",
       "         5.25014736e-02, -3.65396030e-03,  4.76078615e-02,  1.58372764e-02,\n",
       "         2.03388259e-02,  4.35362570e-02, -3.29167186e-03,  2.03181785e-02,\n",
       "         1.88023411e-03, -4.23493721e-02,  5.44102443e-03,  3.70935947e-02,\n",
       "        -1.65622663e-02,  6.48645638e-03, -4.78012040e-02,  8.67484324e-03,\n",
       "         5.88859580e-02, -3.21394317e-02,  4.32439968e-02,  9.65300482e-03,\n",
       "        -4.47920570e-03, -1.94858182e-02, -3.63502875e-02, -1.23471767e-02,\n",
       "        -2.17929184e-02, -1.99016239e-02,  8.09619799e-02, -3.32986489e-02,\n",
       "        -2.38901116e-02, -3.96138951e-02, -1.27279749e-02,  3.50380726e-02,\n",
       "        -2.52217241e-02,  2.00030743e-03,  1.49660828e-02, -2.31976565e-02,\n",
       "        -6.86791465e-02, -5.25778159e-04, -2.22545806e-02, -1.04103768e-02,\n",
       "        -1.96115170e-02, -5.11167347e-02, -3.00412849e-02, -4.71472368e-02,\n",
       "        -6.60407022e-02, -6.53187744e-03,  4.47769649e-02,  5.17136138e-03,\n",
       "        -2.09416114e-02,  1.23682676e-03,  2.28888318e-02, -1.85612414e-03,\n",
       "        -7.21752830e-03,  7.72090480e-02, -4.45430689e-02,  1.07156057e-02,\n",
       "        -1.00543592e-02,  2.43769921e-02, -5.69796301e-02,  3.43469530e-02,\n",
       "        -4.38812263e-02, -4.87334505e-02,  1.07071465e-02, -4.02080128e-03,\n",
       "        -4.04056013e-02, -1.38860960e-02,  7.36653013e-03, -1.29188905e-02,\n",
       "         1.98347531e-02,  5.15974015e-02,  1.53137585e-02,  6.00985289e-02,\n",
       "         2.91915201e-02,  2.13116352e-02,  1.05796680e-02, -1.75736975e-02,\n",
       "        -1.27161611e-02,  1.49260415e-02, -3.67730595e-02,  2.80872434e-02,\n",
       "        -7.37118255e-03, -3.20464559e-02, -6.50109202e-02, -2.11241879e-02,\n",
       "         1.02156093e-02,  1.08291227e-02,  2.33738348e-02, -3.79535519e-02,\n",
       "        -2.52659316e-04,  1.23480689e-02,  4.79921885e-03,  1.14297622e-03,\n",
       "         1.29668675e-02, -1.79976411e-02, -6.43284842e-02, -2.44849902e-02,\n",
       "        -5.11866622e-02,  4.14219089e-02,  2.92939283e-02, -1.51848197e-01,\n",
       "         4.36054282e-02,  3.35993432e-03, -1.57337096e-02, -1.68261584e-02,\n",
       "        -4.11889404e-02, -4.19662148e-02,  3.85781899e-02,  2.93741487e-02,\n",
       "         1.88560616e-02,  6.75268993e-02, -7.35579571e-03,  8.21799040e-03,\n",
       "         4.07199971e-02,  1.03858393e-02, -2.17650980e-02,  5.34508266e-02,\n",
       "        -1.53584713e-02, -2.10202336e-02, -1.74071640e-02, -3.29134092e-02,\n",
       "         1.69050228e-02,  4.25001919e-01, -4.37945463e-02,  4.46010288e-03,\n",
       "         1.76204834e-02, -1.57659482e-02, -5.26642539e-02,  5.28488271e-02,\n",
       "         1.84012204e-03, -3.39380801e-02, -1.30728800e-02, -3.59011292e-02,\n",
       "         3.76180676e-03,  3.87275629e-02, -2.52379980e-02, -1.17168576e-02,\n",
       "        -1.85121484e-02, -1.07054748e-02,  6.98609231e-03,  4.01850194e-02,\n",
       "         6.46593496e-02, -4.49310010e-03, -4.05048020e-02, -6.70560524e-02,\n",
       "        -6.74298480e-02,  6.93303719e-03,  3.56784239e-02, -2.30640024e-02,\n",
       "         1.13911154e-02,  4.64895274e-03, -4.67326306e-03, -2.93388441e-02,\n",
       "         2.70005483e-02,  2.80503165e-02,  1.54877622e-02,  4.98288199e-02,\n",
       "         1.75895379e-03,  1.59470662e-02, -1.87687688e-02,  2.38400474e-02,\n",
       "        -3.52132395e-02, -5.26169017e-02,  2.41551343e-02, -3.68120968e-02,\n",
       "        -2.27651075e-02, -1.65995490e-02,  6.62984475e-02,  4.72906418e-02,\n",
       "        -3.74228097e-02,  4.02233526e-02, -4.16416340e-02,  5.67453727e-03,\n",
       "         6.06894046e-02, -2.65664980e-02,  4.06133719e-02,  3.00408676e-02,\n",
       "         7.32574658e-03,  7.61863170e-03,  4.46414016e-02,  7.99625739e-03,\n",
       "         3.42843197e-02,  3.69458459e-02, -3.14736068e-02,  5.91586791e-02,\n",
       "        -1.93830468e-02,  6.43222928e-02,  3.22228894e-02, -6.08226610e-03,\n",
       "        -3.56931443e-04,  9.86458641e-03, -1.57797057e-02,  3.34350131e-02,\n",
       "        -4.46309661e-03, -1.63690152e-03,  4.39812355e-02, -2.97544301e-02,\n",
       "        -5.51465936e-02, -1.35631384e-02, -4.74109165e-02, -1.53332939e-02,\n",
       "         1.75195821e-02, -3.07430755e-02, -6.16585389e-02, -1.85414159e-03,\n",
       "        -7.01818988e-03,  2.12448481e-02, -2.42551952e-03, -5.68780256e-03,\n",
       "         7.10657761e-02, -8.37227236e-03, -2.79168263e-02,  2.05669757e-02,\n",
       "         1.80451456e-03,  2.59759221e-02, -1.15979062e-02,  1.05833998e-02,\n",
       "         6.48899302e-02, -1.04813529e-02,  8.43627378e-04, -8.50323681e-03,\n",
       "        -5.45838028e-02, -5.02442196e-02, -2.42581945e-02, -4.58891764e-02,\n",
       "        -2.73674484e-02, -3.71859968e-02, -1.69388093e-02,  3.86053836e-03,\n",
       "        -1.51375227e-03,  2.32304055e-02, -8.20591114e-03, -5.83853282e-04,\n",
       "        -3.10665113e-03,  4.16648434e-03,  1.92136206e-02, -3.45781334e-02,\n",
       "         1.72270443e-02, -1.64893679e-02, -5.55125391e-03, -1.03297466e-02,\n",
       "         3.63707617e-02, -8.18510726e-03, -1.89420383e-03,  2.80163903e-02,\n",
       "        -5.14980815e-02,  7.25948960e-02, -2.09429450e-02, -2.51389518e-02,\n",
       "        -2.79839849e-03, -1.17756799e-02, -3.84836979e-02,  2.46885587e-02,\n",
       "        -7.74489762e-03, -2.22943351e-02,  4.15773168e-02,  7.26592541e-02,\n",
       "         4.90002520e-02, -4.25625406e-02, -3.42780463e-02,  1.13822743e-02,\n",
       "         1.28215821e-02,  3.65284495e-02, -7.14555159e-02,  2.35049482e-02,\n",
       "         2.21516751e-02,  1.25494823e-02,  3.66669744e-02, -7.28751579e-03,\n",
       "         2.29848139e-02, -1.54457493e-02,  1.78446632e-03, -1.90553423e-02,\n",
       "         4.37000301e-03, -7.02115055e-03,  1.12454090e-02, -8.95215757e-03,\n",
       "         3.34546678e-02,  4.76906858e-02, -8.17534029e-02, -2.05467530e-02,\n",
       "         1.26276333e-02,  2.46593375e-02, -2.34584510e-02,  2.30956264e-02,\n",
       "         4.73870477e-03, -4.06231619e-02, -5.14064031e-03, -5.11260610e-03,\n",
       "        -1.87988058e-02, -9.51300561e-03, -4.06610146e-02, -5.94680198e-03,\n",
       "        -1.70054007e-02,  1.50673185e-02,  2.66338494e-02,  5.69822686e-03,\n",
       "         1.17724976e-02,  5.24606779e-02,  1.03016356e-02, -1.11168278e-02,\n",
       "         4.26220179e-01,  9.18332580e-03, -2.24644821e-02,  2.56594394e-05,\n",
       "         2.53463332e-02,  1.10827212e-03,  1.99251231e-02, -1.99981630e-02,\n",
       "        -4.37211730e-02,  3.78218889e-02, -2.89321076e-02, -5.03923073e-02,\n",
       "        -1.59865804e-02, -7.98651390e-03, -6.10551685e-02, -5.79015464e-02,\n",
       "         3.64041254e-02,  1.32154390e-01,  2.63348985e-02, -1.76311063e-03,\n",
       "        -1.95033830e-02, -7.45859882e-03,  3.09366751e-02, -7.06170052e-02,\n",
       "        -2.92609390e-02,  3.19207013e-02, -4.12236759e-03, -1.22665579e-03,\n",
       "         1.29283231e-03,  1.08488193e-02,  3.70535739e-02,  2.48648506e-02,\n",
       "         5.92989437e-02, -1.38130253e-02, -2.59326641e-02,  1.89559646e-02,\n",
       "        -1.21582113e-02, -1.44583108e-02,  4.56413887e-02, -1.11835822e-02,\n",
       "        -2.17036251e-02, -1.99640431e-02, -3.57390903e-02, -5.62390797e-02,\n",
       "        -3.62788700e-02,  2.04109517e-03, -6.21685898e-03,  2.86480621e-03,\n",
       "         2.45198272e-02, -2.52743140e-02, -1.87304839e-02, -4.26104367e-02,\n",
       "        -7.79900253e-02,  3.04665472e-02,  2.10640170e-02,  7.06648529e-02,\n",
       "         1.94356851e-02,  6.74400330e-02, -3.53914239e-02,  1.65051278e-02,\n",
       "         3.67444125e-03,  1.81801710e-02,  3.24926488e-02,  7.36143142e-02,\n",
       "         2.41952389e-02, -5.57403229e-02,  5.82811162e-02, -4.75137644e-02,\n",
       "         1.36917150e-02, -4.21428941e-02,  5.79718761e-02, -1.29638221e-02,\n",
       "        -3.83988135e-02,  8.61266702e-02,  7.02567771e-02,  4.58456669e-03,\n",
       "        -2.20486969e-02,  3.03836782e-02,  2.21410748e-02, -1.06170097e-04,\n",
       "         2.45712772e-02,  4.81939688e-03,  8.94928649e-02,  4.47986722e-02,\n",
       "        -5.43402731e-02,  1.29984301e-02, -7.96520151e-03,  5.46420440e-02,\n",
       "         4.41766866e-02,  6.39600167e-03, -8.61337222e-03, -5.03848754e-02,\n",
       "        -1.96266286e-02, -7.09272772e-02, -3.81454788e-02,  2.60177813e-02,\n",
       "        -2.14516278e-02,  1.67377340e-03, -3.15811336e-02, -1.01632373e-02,\n",
       "         5.47311530e-02, -3.02973669e-02,  7.97360670e-03, -3.90923843e-02,\n",
       "        -1.47981523e-02, -1.64482612e-02, -1.83397755e-02, -4.25217599e-02,\n",
       "         5.81512563e-02, -6.97389320e-02, -5.11610508e-02, -5.93192764e-02,\n",
       "         2.87116114e-02, -3.98670137e-02, -1.55106587e-02, -6.82009105e-03,\n",
       "        -6.87440708e-02, -1.56711936e-02, -8.30530538e-04,  5.69929294e-02,\n",
       "         9.76887718e-03,  1.99994482e-02, -3.99629623e-02, -2.07548612e-03,\n",
       "         7.32859969e-03, -8.19035398e-04, -3.02243605e-02,  3.75216231e-02,\n",
       "        -3.09377927e-02, -9.52286366e-03,  4.03511338e-02, -3.51577699e-02,\n",
       "        -4.35718596e-02,  1.54990214e-03,  2.40377802e-02, -1.07403304e-02,\n",
       "        -2.14404184e-02, -3.50492410e-02, -6.07149750e-02,  5.72835142e-03,\n",
       "        -2.99396515e-02, -9.97055206e-04,  1.78252105e-02, -3.99326161e-02,\n",
       "        -4.67348248e-02,  1.17538301e-02,  6.69429079e-03,  1.21372538e-02,\n",
       "         2.07599364e-02,  7.66247325e-03,  3.38404207e-03, -4.85173650e-02,\n",
       "         5.47078662e-02, -1.01764435e-02, -4.31973971e-02,  2.08097347e-03,\n",
       "         4.48220782e-02, -3.24081779e-02,  2.62965169e-02, -2.22246628e-02,\n",
       "        -1.57362188e-03, -3.87510061e-02, -2.12445166e-02, -2.06599459e-02,\n",
       "        -7.92941451e-03, -5.09926155e-02,  1.86651517e-02, -7.98922628e-02,\n",
       "        -9.26912297e-03, -8.15474913e-02, -7.10682943e-03,  6.17292635e-02,\n",
       "         5.66982739e-02, -6.17756695e-03, -8.92665461e-02, -2.18616035e-02,\n",
       "        -1.76050384e-02,  2.18748879e-02,  5.68496101e-02, -4.83405311e-03,\n",
       "         2.70048343e-02,  1.00954674e-01,  1.54861733e-02,  4.39982414e-02,\n",
       "         8.52167699e-03,  1.52394315e-02, -1.68982018e-02, -3.72863561e-02,\n",
       "        -4.72998247e-02, -4.71986979e-02, -1.83405224e-02,  6.12210110e-02,\n",
       "         4.89988439e-02,  2.21092515e-02, -4.09185253e-02,  2.38486356e-03,\n",
       "         1.40488353e-02, -3.85090546e-03,  2.97772214e-02, -1.06853149e-04],\n",
       "       dtype=float32),\n",
       " array([ 1.73233766e-02, -1.32769095e-02, -2.42703091e-02,  3.84329893e-02,\n",
       "         1.08081819e-02, -5.86465225e-02,  2.29125917e-02,  6.74869493e-02,\n",
       "         4.06084694e-02,  1.29939034e-03,  4.29866603e-03, -2.49144365e-03,\n",
       "        -5.68564758e-02, -2.10358221e-02,  3.03448010e-02, -1.62468385e-02,\n",
       "         2.49860398e-02, -4.18759929e-03, -1.45019349e-02, -1.03967972e-02,\n",
       "         1.44381747e-02,  9.27796029e-03,  3.10424827e-02, -2.87954905e-03,\n",
       "         1.45213734e-02,  3.06814089e-02, -6.94430545e-02,  4.24876343e-03,\n",
       "         2.95645464e-02, -3.61431241e-02,  9.63681843e-03,  1.62329171e-02,\n",
       "         2.33894065e-02,  1.11387325e-02,  4.35175048e-03,  2.09859945e-03,\n",
       "         7.63531891e-04,  8.88351351e-03,  2.59089679e-03, -1.11683056e-01,\n",
       "        -2.35922802e-02, -2.17377464e-03, -1.86665505e-02,  2.37779114e-02,\n",
       "        -1.48263453e-02, -2.55657062e-02, -2.96970247e-03, -8.63739569e-03,\n",
       "         7.52162607e-03, -1.19852070e-02,  3.99882346e-03, -1.12456167e-02,\n",
       "        -7.14541227e-03, -3.29842754e-02, -2.20877584e-03, -9.74047754e-04,\n",
       "        -1.50438407e-02,  1.07568549e-02,  1.24463942e-02,  2.42400728e-02,\n",
       "         8.47542717e-04,  3.10147618e-04, -3.65618314e-03, -1.26144961e-02,\n",
       "         9.12839640e-03, -1.73661567e-03, -2.20067017e-02,  1.32873422e-02,\n",
       "        -1.30774835e-02,  3.81288468e-03, -2.49434654e-02,  9.97177046e-03,\n",
       "         2.33864449e-02, -4.63878689e-03, -4.80101182e-04,  1.14333518e-02,\n",
       "        -5.71461918e-04, -1.58870965e-02, -6.70711789e-03, -7.78361931e-02,\n",
       "        -2.13615652e-02, -3.01873833e-02,  3.11301067e-03,  3.90018821e-02,\n",
       "        -2.02592742e-02,  4.29197550e-02,  1.76692698e-02, -1.85818039e-02,\n",
       "         2.14766227e-02, -1.23277828e-02, -2.82176696e-02, -1.10760089e-02,\n",
       "        -7.43468106e-01,  3.14509720e-02,  7.19550671e-03, -5.90758864e-03,\n",
       "         1.93705987e-02, -1.50000174e-02, -9.10245348e-04, -3.01336516e-02,\n",
       "         1.69085134e-02, -2.04979498e-02,  2.76833456e-02,  4.59232647e-03,\n",
       "         4.31411602e-02,  8.78548436e-03, -2.39554614e-01,  5.29538188e-03,\n",
       "         2.03203186e-02,  1.23221260e-02, -2.91763223e-03, -5.68720885e-02,\n",
       "        -3.19049209e-02, -2.09228508e-02, -1.45951370e-02,  4.48053674e-04,\n",
       "        -1.16885062e-02, -8.78878869e-03,  4.10809927e-03, -7.82864075e-03,\n",
       "        -1.45864291e-02,  4.38218974e-02, -1.50583228e-02,  2.41901241e-02,\n",
       "         1.22709535e-02, -3.96708678e-03, -2.51476765e-02,  1.21564623e-02,\n",
       "        -6.43814495e-03, -1.45541122e-02,  4.50946391e-02, -7.51870684e-03,\n",
       "         7.71589298e-03,  9.15407166e-02,  7.54818041e-03,  5.00941416e-03,\n",
       "         1.58454273e-02, -3.63433063e-02, -2.68157683e-02,  8.72428715e-03,\n",
       "        -2.07257755e-02, -5.39549887e-02,  5.42286504e-03,  6.14290452e-03,\n",
       "        -1.72426626e-02,  4.78928472e-04, -1.68989152e-02,  2.36722492e-02,\n",
       "        -2.18700035e-03, -4.45315912e-02,  2.08612457e-02, -1.99679229e-02,\n",
       "         3.94839756e-02, -2.14489605e-02, -9.52543225e-03, -3.73376943e-02,\n",
       "        -2.15380844e-02, -3.08293360e-03,  2.03903858e-02,  1.03682149e-02,\n",
       "         3.12501229e-02, -2.77676620e-03, -3.53349596e-02, -4.32232358e-02,\n",
       "         3.00411694e-02, -1.65650330e-03,  2.29018950e-03,  1.91441514e-02,\n",
       "        -4.28956421e-03,  2.16600318e-02, -4.32142802e-02, -6.89827418e-03,\n",
       "        -1.11628547e-02, -1.96522009e-03, -1.10079478e-02, -2.72619594e-02,\n",
       "        -1.12970481e-02, -2.41885241e-02,  6.89323321e-02,  3.27075832e-02,\n",
       "        -1.93929207e-03, -2.95470953e-02, -1.56383831e-02, -4.19402262e-03,\n",
       "        -2.04448006e-03, -4.19646269e-03,  2.13772226e-02, -1.34302555e-02,\n",
       "         4.95372864e-04,  4.79386840e-03,  3.11526190e-02,  1.97138619e-02,\n",
       "         2.88093439e-03, -1.05174258e-03, -1.24168014e-02,  8.07112176e-03,\n",
       "         7.96766020e-03,  2.40298714e-02,  3.71446833e-03, -1.15476629e-04,\n",
       "         4.92546633e-02, -3.15254852e-02, -1.10915229e-02,  7.95912230e-04,\n",
       "        -1.83758326e-02,  2.00046860e-02,  9.84637300e-04,  1.93867814e-02,\n",
       "         2.25409809e-02,  2.24836380e-03,  4.23466088e-03,  5.64086549e-02,\n",
       "         2.33497284e-02, -1.87314507e-02, -8.62108730e-03,  2.65889410e-02,\n",
       "        -1.05799222e-02,  2.91583315e-02,  9.80665069e-03, -6.76940847e-03,\n",
       "         5.22445887e-02,  6.66235061e-03,  7.86664803e-03,  2.66831052e-02,\n",
       "         1.46752205e-02, -6.56918623e-03,  7.19964737e-03, -3.80563620e-03,\n",
       "         1.50154307e-02,  4.48516198e-02,  7.43426057e-03, -2.11686678e-02,\n",
       "         1.61456931e-02, -5.26765622e-02,  8.93959869e-03, -1.68019868e-02,\n",
       "        -8.72700289e-03, -4.63086031e-02, -5.35116997e-03,  1.23415850e-02,\n",
       "         1.17042568e-02,  5.26783895e-03,  2.85609644e-02,  2.26699817e-03,\n",
       "        -4.53217067e-02,  3.33808698e-02,  2.28392072e-02,  9.03763901e-03,\n",
       "        -1.19447224e-02, -1.47219133e-02, -1.34710288e-02, -3.54388282e-02,\n",
       "         4.51713391e-02, -2.35705674e-02, -1.45591823e-02,  1.05670011e-02,\n",
       "         2.26198528e-02, -6.23546354e-03, -5.28014004e-02, -3.07213757e-02,\n",
       "         8.10620782e-04, -6.33502472e-03, -1.87177700e-03,  7.70982355e-02,\n",
       "        -7.50694470e-03,  1.21101020e-02, -3.94118987e-02,  2.54239906e-02,\n",
       "         2.71509141e-02,  2.65577491e-02,  2.80897226e-02,  7.18820188e-03,\n",
       "         1.32341553e-02, -2.24709157e-02, -1.02123674e-02,  1.63854007e-02,\n",
       "         6.47270214e-03, -2.27258634e-02,  4.47176881e-02, -7.65575888e-03,\n",
       "         2.94588953e-02,  3.06369532e-02, -1.38544533e-02,  1.78468525e-02,\n",
       "         1.14358142e-02,  3.02426852e-02, -4.81964909e-02, -1.08771613e-02,\n",
       "        -2.58970750e-03, -7.60373147e-03, -3.25113302e-03, -8.60510487e-03,\n",
       "        -4.54963977e-03, -4.65721241e-04, -7.54331332e-03,  6.66226745e-02,\n",
       "        -1.04685746e-01, -1.26701398e-02,  2.94671650e-03, -1.74584482e-02,\n",
       "        -7.90367927e-03, -4.42067832e-02, -2.97285337e-02,  4.13948782e-02,\n",
       "        -3.35627496e-02, -2.32572407e-02,  1.06734037e-02,  4.55172323e-02,\n",
       "         2.68479586e-02,  1.36055946e-02, -3.50506902e-02,  2.30056569e-02,\n",
       "         9.16135088e-02,  5.99744841e-02, -2.30844412e-02,  5.44097647e-02,\n",
       "        -4.06661211e-03,  1.93821918e-02, -4.92541231e-02, -2.40473747e-02,\n",
       "         2.83119604e-02,  3.37822288e-02, -2.43736766e-02,  1.22593688e-02,\n",
       "        -4.56870534e-03, -2.77118981e-02,  2.06844267e-02, -4.28982228e-02,\n",
       "         3.22350971e-02,  5.45085147e-02, -2.04529669e-02,  1.62302703e-02,\n",
       "         7.54603231e-03, -2.10341569e-02, -1.97170563e-02, -2.37408746e-02,\n",
       "         3.95001052e-03,  9.31580272e-03,  2.60739271e-02, -1.89504260e-03,\n",
       "         9.75736883e-03, -3.31628066e-03, -2.14964561e-02,  1.90837495e-02,\n",
       "        -1.38261365e-02, -1.24583337e-02,  1.58143211e-02, -5.40697062e-03,\n",
       "         6.34250510e-03,  1.28692901e-02,  3.43649909e-02,  2.28652544e-02,\n",
       "         3.27092484e-02, -2.92666312e-02,  2.44341753e-02,  2.21293177e-02,\n",
       "        -2.36848015e-02, -2.64882762e-02, -1.44471005e-02,  3.71305160e-02,\n",
       "        -8.02748464e-03, -8.07765964e-03,  2.00023390e-02, -8.36271886e-03,\n",
       "        -1.06923051e-01,  2.41233278e-02,  1.45965042e-02,  5.90559728e-02,\n",
       "         3.58874872e-02, -9.88143682e-03, -3.64120901e-02,  4.79857950e-03,\n",
       "        -1.19278273e-02,  9.97235812e-03,  2.57199071e-02, -3.79226580e-02,\n",
       "        -4.31579649e-02,  3.10490769e-03, -1.96157694e-02,  1.57715604e-02,\n",
       "        -5.21985851e-02, -3.88779826e-02,  1.18391206e-02, -1.94461867e-02,\n",
       "         1.04660187e-02,  4.37754244e-02,  1.10417418e-02, -1.83045045e-02,\n",
       "        -3.66856121e-02,  1.96482763e-02, -7.29204938e-02, -4.79351543e-03,\n",
       "         1.02031638e-03,  2.24663247e-03,  7.96706323e-03,  8.95653665e-03,\n",
       "         1.99719053e-02, -3.88573296e-02, -1.04435459e-02, -2.34200992e-02,\n",
       "        -7.41179753e-03,  5.01531363e-03,  7.73338787e-03, -3.10517848e-02,\n",
       "        -3.71029042e-02,  9.69723240e-03, -3.65896150e-02, -4.80168127e-03,\n",
       "         4.75269333e-02, -5.16862050e-02,  2.64497809e-02, -1.64460354e-02,\n",
       "         3.87516692e-02, -1.29164821e-02,  1.83947142e-02,  3.69979292e-02,\n",
       "        -4.10803407e-02, -2.40276959e-02,  5.00602601e-03, -4.72481027e-02,\n",
       "        -2.73879385e-03, -1.15774274e-02,  5.92237385e-03, -4.60090302e-02,\n",
       "         1.39353620e-02,  5.30959151e-05,  2.32697111e-02, -7.12188892e-03,\n",
       "        -1.80835634e-01, -1.08445191e-03, -8.43477901e-04,  3.09297536e-03,\n",
       "        -1.89810190e-02, -2.65244748e-02, -3.47997695e-02,  8.00165907e-03,\n",
       "         3.01174186e-02, -2.11426094e-02,  1.29353981e-02, -2.72495393e-02,\n",
       "        -1.13432957e-02, -3.14719090e-03, -3.16662677e-02, -1.39420130e-03,\n",
       "        -4.65529375e-02,  1.83134694e-02,  2.15279702e-02, -1.44490199e-02,\n",
       "        -3.21004819e-03, -2.71646981e-03, -7.53619894e-03, -2.65845340e-02,\n",
       "        -2.59252917e-02, -3.15151475e-02, -8.08552653e-03,  1.08348383e-02,\n",
       "        -1.01363277e-02,  1.22824300e-03, -9.38913971e-03,  1.23432837e-02,\n",
       "         1.68233039e-03,  2.40754653e-02, -2.46718023e-02, -2.05100980e-02,\n",
       "         1.39257740e-02,  3.34403967e-03,  5.49226217e-02, -8.18423461e-03,\n",
       "         2.73219012e-02, -2.60804985e-02,  1.48731740e-02, -2.81532947e-02,\n",
       "         2.28353962e-02, -1.25428289e-02, -4.04235302e-03, -4.06169333e-02,\n",
       "         8.03131517e-03, -2.05622278e-02, -1.60063412e-02, -2.82644704e-02,\n",
       "        -9.02639888e-03,  1.38345174e-02, -5.33894217e-03,  3.65106873e-02,\n",
       "         6.47848146e-03, -3.67799848e-02, -1.13036297e-02,  1.25494972e-02,\n",
       "        -4.16554324e-02, -3.91954407e-02,  5.28055523e-03, -1.27066160e-02,\n",
       "         7.78124621e-03, -2.29800045e-02, -2.66525010e-03,  1.35377729e-02,\n",
       "        -5.03081009e-02,  9.08678025e-03,  1.50720784e-02, -2.35492140e-02,\n",
       "        -1.67366751e-02,  1.29969446e-02,  1.84124447e-02,  3.33823264e-03,\n",
       "        -2.81119738e-02, -2.47434322e-02, -3.17216152e-03,  3.42064165e-02,\n",
       "         9.67477635e-03,  8.99405107e-02, -2.72155274e-03,  3.25303823e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c861960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'type': 'text'}, page_content='Annual Revenue Overview\\nThis document summarizes the revenue trends across Q1, Q2, and Q3. As illustrated in the chart\\nbelow, revenue grew steadily with the highest growth recorded in Q3.\\nQ1 showed a moderate increase in revenue as new product lines were introduced. Q2 outperformed\\nQ1 due to marketing campaigns. Q3 had exponential growth due to global expansion.'),\n",
       " Document(metadata={'page': 0, 'type': 'image', 'image_id': 'page_0_image_0'}, page_content='[Image: page_0_image_0]')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ab0b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1fc0a2fe410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating vector store\n",
    "embeddings_array = np.array(all_embeddings)\n",
    "\n",
    "vector_store = FAISS.from_embeddings(\n",
    "    text_embeddings=[(doc.page_content, emb) for doc, emb in zip(all_docs, embeddings_array)],\n",
    "    embedding=None, # using pre-computed embeddings\n",
    "    metadatas=[doc.metadata for doc in all_docs]\n",
    ")\n",
    "\n",
    "vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2d46de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCohere(client=<cohere.client.Client object at 0x000001FC0CE66010>, async_client=<cohere.client.AsyncClient object at 0x000001FC0C8B2050>, model=' command-r', cohere_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "llm = init_chat_model('cohere: command-r') # it's not a multimodal so this llm won't work\n",
    "\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96761001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Cohere model with OpenAI's multimodal model\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4-vision-preview')\n",
    "# or use: llm = init_chat_model('openai:gpt-4o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "626261c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to retrieve relevant info from vector store\n",
    "def retrieve(query, k=5):\n",
    "    query_embeddings = embed_text(query)\n",
    "    \n",
    "    # search vector store\n",
    "    results = vector_store.similarity_search_by_vector(\n",
    "        embedding=query_embeddings,\n",
    "        k = k # count of vectors to fetch\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b1e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template(query, retrieved_docs):\n",
    "    content = []\n",
    "    \n",
    "    content.append({\n",
    "        'type': 'text',\n",
    "        'text': f\"Question: {query} \\n\\n context: \\n\"\n",
    "    })\n",
    "    \n",
    "    # differentiate the text and image docs\n",
    "    text_docs = [doc for doc in retrieved_docs if doc.metadata.get('type') == 'text']\n",
    "    image_docs = [doc for doc in retrieved_docs if doc.metadata.get('type') == 'image']\n",
    "    \n",
    "    # define context\n",
    "    if text_docs:\n",
    "        text_context = \"\\n\\n\".join([\n",
    "            f\"[Page {doc.metadata['page']}]: {doc.page_content}\"\n",
    "            for doc in text_docs\n",
    "        ])\n",
    "        content.append({\n",
    "            'type': \"text\",\n",
    "            'text': f\"text excerpts: \\n{text_context}\\n\"\n",
    "        })\n",
    "        \n",
    "    # provide images\n",
    "    for doc in image_docs:\n",
    "        image_id = doc.metadata.get('image_id')\n",
    "        if image_id and image_id in image_data_store:\n",
    "            content.append({\n",
    "                'type': 'text',\n",
    "                'text': f\"\\n[Image from page {doc.metadata['page']}]: \\n\"\n",
    "            })\n",
    "            content.append({\n",
    "                'type': 'image_url',\n",
    "                'image_url': {\n",
    "                    'url': f'data: image/png; base64, {image_data_store[image_id]}'\n",
    "                }\n",
    "            })\n",
    "            \n",
    "    content.append({\n",
    "        'type': 'text',\n",
    "        'text': '\\n\\n Please answer the question based on the provided text and images.'\n",
    "    })\n",
    "    \n",
    "    return HumanMessage(content=content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dd342c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template_for_cohere(query, retrieved_docs):\n",
    "    # Build a text-only prompt since Cohere doesn't support multimodal input\n",
    "    prompt_parts = [f\"Question: {query}\\n\\nContext:\\n\"]\n",
    "    \n",
    "    # differentiate the text and image docs\n",
    "    text_docs = [doc for doc in retrieved_docs if doc.metadata.get('type') == 'text']\n",
    "    image_docs = [doc for doc in retrieved_docs if doc.metadata.get('type') == 'image']\n",
    "    \n",
    "    # Add text context\n",
    "    if text_docs:\n",
    "        text_context = \"\\n\\n\".join([\n",
    "            f\"[Page {doc.metadata['page']}]: {doc.page_content}\"\n",
    "            for doc in text_docs\n",
    "        ])\n",
    "        prompt_parts.append(f\"Text excerpts:\\n{text_context}\\n\")\n",
    "    \n",
    "    # Add image descriptions (since we can't send actual images to Cohere)\n",
    "    if image_docs:\n",
    "        image_descriptions = []\n",
    "        for doc in image_docs:\n",
    "            image_descriptions.append(f\"[Image on page {doc.metadata['page']}]\")\n",
    "        prompt_parts.append(f\"Images found:\\n\" + \"\\n\".join(image_descriptions) + \"\\n\")\n",
    "    \n",
    "    prompt_parts.append(\"\\nPlease answer the question based on the provided text context and knowledge of any images mentioned.\")\n",
    "    \n",
    "    # Return a simple HumanMessage with text content only\n",
    "    return HumanMessage(content=\"\".join(prompt_parts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9a66d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query):\n",
    "    # retrieve relevant docs\n",
    "    context_docs = retrieve(query, k = 5)\n",
    "    \n",
    "    # create message\n",
    "    # message = prompt_template(query, context_docs)\n",
    "    message = prompt_template_for_cohere(query, context_docs)\n",
    "    \n",
    "    # get response\n",
    "    response = llm.invoke([message])\n",
    "    \n",
    "    print(f'\\n REtrieved {len(context_docs)} documents: ')\n",
    "    for doc in context_docs:\n",
    "        doc_type = doc.metadata.get(\"type\", 'unknown')\n",
    "        page = doc.metadata.get('page', '?')\n",
    "        if doc_type == 'text':\n",
    "            preview = doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content\n",
    "            print(f\" - text from page {page}: {preview}\")\n",
    "        else:\n",
    "            print(f\" - image from page {page}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc4e4e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What does the chart on page 1 show about revenue trends?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "status_code: 404, body: {'id': '5292f0fa-7e36-4eb4-9da2-19a0d7fc8f05', 'message': \"model ' command-r' not found, make sure the correct model ID was used and that you have access to the model.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m answer = \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrag_pipeline\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      7\u001b[39m message = prompt_template_for_cohere(query, context_docs)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# get response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m REtrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(context_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents: \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m context_docs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    275\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m     **kwargs: Any,\n\u001b[32m    280\u001b[39m ) -> BaseMessage:\n\u001b[32m    281\u001b[39m     config = ensure_config(config)\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    283\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    294\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    854\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    857\u001b[39m     **kwargs: Any,\n\u001b[32m    858\u001b[39m ) -> LLMResult:\n\u001b[32m    859\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    689\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    696\u001b[39m         )\n\u001b[32m    697\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    929\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\langchain_cohere\\chat_models.py:1135\u001b[39m, in \u001b[36mChatCohere._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[32m   1132\u001b[39m request = get_cohere_chat_request_v2(\n\u001b[32m   1133\u001b[39m     messages, stop_sequences=stop, **\u001b[38;5;28mself\u001b[39m._default_params, **kwargs\n\u001b[32m   1134\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m generation_info = \u001b[38;5;28mself\u001b[39m._get_generation_info_v2(\n\u001b[32m   1138\u001b[39m     response, request.get(\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1139\u001b[39m )\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative-AI\\venv\\Lib\\site-packages\\cohere\\v2\\client.py:626\u001b[39m, in \u001b[36mV2Client.chat\u001b[39m\u001b[34m(self, model, messages, tools, strict_tools, documents, citation_options, response_format, safety_mode, max_tokens, stop_sequences, temperature, seed, frequency_penalty, presence_penalty, k, p, return_prompt, logprobs, tool_choice, request_options)\u001b[39m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenError(\n\u001b[32m    617\u001b[39m         typing.cast(\n\u001b[32m    618\u001b[39m             typing.Optional[typing.Any],\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         )\n\u001b[32m    624\u001b[39m     )\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[32m    627\u001b[39m         typing.cast(\n\u001b[32m    628\u001b[39m             typing.Optional[typing.Any],\n\u001b[32m    629\u001b[39m             construct_type(\n\u001b[32m    630\u001b[39m                 type_=typing.Optional[typing.Any],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    631\u001b[39m                 object_=_response.json(),\n\u001b[32m    632\u001b[39m             ),\n\u001b[32m    633\u001b[39m         )\n\u001b[32m    634\u001b[39m     )\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m422\u001b[39m:\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityError(\n\u001b[32m    637\u001b[39m         typing.cast(\n\u001b[32m    638\u001b[39m             typing.Optional[typing.Any],\n\u001b[32m   (...)\u001b[39m\u001b[32m    643\u001b[39m         )\n\u001b[32m    644\u001b[39m     )\n",
      "\u001b[31mNotFoundError\u001b[39m: status_code: 404, body: {'id': '5292f0fa-7e36-4eb4-9da2-19a0d7fc8f05', 'message': \"model ' command-r' not found, make sure the correct model ID was used and that you have access to the model.\"}"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What does the chart on page 1 show about revenue trends?\",\n",
    "        \"Summarize the main findings from the document\",\n",
    "        \"What visual elements are present in the document?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "        answer = rag_pipeline(query)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e1fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae88aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
